{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç”ŸæˆinstructæŒ‡ä»¤æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "æ­£å…‹éš†åˆ° 'stanford_alpaca'...\n",
      "remote: Enumerating objects: 129, done.\u001b[K\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 129 (delta 55), reused 52 (delta 50), pack-reused 56\u001b[K\n",
      "æ¥æ”¶å¯¹è±¡ä¸­: 100% (129/129), 9.15 MiB | 2.67 MiB/s, done.\n",
      "å¤„ç† delta ä¸­: 100% (61/61), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tatsu-lab/stanford_alpaca.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/zhc/llm/My_ChatGLM_6B_Lora_Tuning_En_And_Zh/stanford_alpaca\n"
     ]
    }
   ],
   "source": [
    "%cd stanford_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: numpy in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.25.0)\n",
      "Collecting rouge_score (from -r requirements.txt (line 2))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fire (from -r requirements.txt (line 3))\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m483.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: openai in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.27.8)\n",
      "Requirement already satisfied: transformers>=4.28.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.30.2)\n",
      "Requirement already satisfied: torch in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: sentencepiece in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.1.99)\n",
      "Requirement already satisfied: tokenizers>=0.13.3 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.13.3)\n",
      "Collecting wandb (from -r requirements.txt (line 9))\n",
      "  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.4.0)\n",
      "Collecting nltk (from rouge_score->-r requirements.txt (line 2))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.16.0)\n",
      "Collecting termcolor (from fire->-r requirements.txt (line 3))\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (3.8.4)\n",
      "Requirement already satisfied: filelock in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (0.3.1)\n",
      "Requirement already satisfied: typing-extensions in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (4.6.3)\n",
      "Requirement already satisfied: sympy in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: networkx in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 6)) (67.8.0)\n",
      "Requirement already satisfied: wheel in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 6)) (0.38.4)\n",
      "Requirement already satisfied: cmake in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 6)) (3.26.4)\n",
      "Requirement already satisfied: lit in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 6)) (16.0.6)\n",
      "Collecting Click!=8.0.0,>=7.0 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading sentry_sdk-1.26.0-py2.py3-none-any.whl (209 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.4/209.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (4.23.3)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9))\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.28.1->-r requirements.txt (line 5)) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 6)) (2.1.3)\n",
      "Collecting joblib (from nltk->rouge_score->-r requirements.txt (line 2))\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 6)) (1.3.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9))\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: rouge_score, fire, pathtools\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=ba2a6d0803fdfe52549029545a9ccee48f5bb5bdc40515c9fc39c583c5d1ab92\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116931 sha256=4ef0f7b0136bfc934c2d811361d25bb91629cd4cfdc8a8d9ae6f8fb66f95933e\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=dc06f4eaa8b52c55997f1e54717e580cae1b56fac9f0833bcdb2915b122c6deb\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "Successfully built rouge_score fire pathtools\n",
      "Installing collected packages: pathtools, appdirs, termcolor, smmap, setproctitle, sentry-sdk, joblib, docker-pycreds, Click, nltk, gitdb, fire, rouge_score, GitPython, wandb\n",
      "Successfully installed Click-8.1.3 GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 fire-0.5.0 gitdb-4.0.10 joblib-1.2.0 nltk-3.8.1 pathtools-0.1.2 rouge_score-0.1.2 sentry-sdk-1.26.0 setproctitle-1.3.2 smmap-5.0.0 termcolor-2.3.0 wandb-0.15.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai \n",
    "openai.api_key = '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'\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä»¥ä¸ŠåŠ è½½å®Œopenai_keyï¼Œ ä»¥ä¸‹å¼€å§‹è¿›è¡Œæ­£å¼æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sys' (built-in)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import imp\n",
    "imp.reload(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe5 in position 210: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrouge_score\u001b[39;00m \u001b[39mimport\u001b[39;00m rouge_scorer\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mutils\u001b[39;00m \n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfire\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/rouge_score/rouge_scorer.py:40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m---> 40\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/nltk/__init__.py:133\u001b[0m\n\u001b[1;32m    125\u001b[0m     subprocess\u001b[39m.\u001b[39mPopen \u001b[39m=\u001b[39m _fake_Popen\n\u001b[1;32m    127\u001b[0m \u001b[39m###########################################################\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# TOP-LEVEL MODULES\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m###########################################################\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[39m# Import top-level functionality into top-level namespace\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcollocations\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecorators\u001b[39;00m \u001b[39mimport\u001b[39;00m decorator, memoize\n\u001b[1;32m    135\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeatstruct\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/nltk/collocations.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_itertools\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# these two unused imports are referenced in collocations.doctest\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     37\u001b[0m     BigramAssocMeasures,\n\u001b[1;32m     38\u001b[0m     ContingencyMeasures,\n\u001b[1;32m     39\u001b[0m     QuadgramAssocMeasures,\n\u001b[1;32m     40\u001b[0m     TrigramAssocMeasures,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspearman\u001b[39;00m \u001b[39mimport\u001b[39;00m ranks_from_scores, spearman_correlation\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprobability\u001b[39;00m \u001b[39mimport\u001b[39;00m FreqDist\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/nltk/metrics/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magreement\u001b[39;00m \u001b[39mimport\u001b[39;00m AnnotationTask\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maline\u001b[39;00m \u001b[39mimport\u001b[39;00m align\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39massociation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     BigramAssocMeasures,\n\u001b[1;32m     20\u001b[0m     ContingencyMeasures,\n\u001b[1;32m     21\u001b[0m     NgramAssocMeasures,\n\u001b[1;32m     22\u001b[0m     QuadgramAssocMeasures,\n\u001b[1;32m     23\u001b[0m     TrigramAssocMeasures,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfusionmatrix\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfusionMatrix\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     binary_distance,\n\u001b[1;32m     28\u001b[0m     custom_distance,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     presence,\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/nltk/metrics/association.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m _SMALL \u001b[39m=\u001b[39m \u001b[39m1e-20\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m fisher_exact\n\u001b[1;32m     27\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfisher_exact\u001b[39m(\u001b[39m*\u001b[39m_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs):\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/stats/__init__.py:485\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m \n\u001b[1;32m    481\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 485\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    486\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[1;32m    487\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/stats/_stats_py.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m cdist\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m \u001b[39mimport\u001b[39;00m _measurements\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/numpy/testing/__init__.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39munittest\u001b[39;00m \u001b[39mimport\u001b[39;00m TestCase\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _private\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (_assert_valid_refcount, _gen_alignment_data)\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m \u001b[39mimport\u001b[39;00m extbuild\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/numpy/testing/_private/utils.py:1257\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1257\u001b[0m _SUPPORTS_SVE \u001b[39m=\u001b[39m check_support_sve()\n\u001b[1;32m   1259\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[39m# assert_raises and assert_raises_regex are taken from unittest.\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39munittest\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/site-packages/numpy/testing/_private/utils.py:1251\u001b[0m, in \u001b[0;36mcheck_support_sve\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1249\u001b[0m cmd \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlscpu\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m     output \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mrun(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, text\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1252\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39msve\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mstdout\n\u001b[1;32m   1253\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    506\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[1;32m   1155\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/subprocess.py:2043\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m   2042\u001b[0m     \u001b[39mif\u001b[39;00m stdout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2043\u001b[0m         stdout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_translate_newlines(stdout,\n\u001b[1;32m   2044\u001b[0m                                           \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m   2045\u001b[0m                                           \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49merrors)\n\u001b[1;32m   2046\u001b[0m     \u001b[39mif\u001b[39;00m stderr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2047\u001b[0m         stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_translate_newlines(stderr,\n\u001b[1;32m   2048\u001b[0m                                           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m   2049\u001b[0m                                           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39merrors)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.10/subprocess.py:1031\u001b[0m, in \u001b[0;36mPopen._translate_newlines\u001b[0;34m(self, data, encoding, errors)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_translate_newlines\u001b[39m(\u001b[39mself\u001b[39m, data, encoding, errors):\n\u001b[0;32m-> 1031\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mdecode(encoding, errors)\n\u001b[1;32m   1032\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe5 in position 210: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json \n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import tqdm \n",
    "from rouge_score import rouge_scorer\n",
    "import utils \n",
    "\n",
    "import fire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Name: rouge-score\n",
      "Version: 0.1.2\n",
      "Summary: Pure python implementation of ROUGE-1.5.5.\n",
      "Home-page: https://github.com/google-research/google-research/tree/master/rouge\n",
      "Author: Google LLC\n",
      "Author-email: rouge-opensource@google.com\n",
      "License: \n",
      "Location: /root/anaconda3/envs/llm/lib/python3.10/site-packages\n",
      "Requires: absl-py, nltk, numpy, six\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGLM-6B + LoRA "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­é—®ç­”çš„å¯¹è¯è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº General Language Model (GLM) æ¶æ„ï¼Œå…·æœ‰ 62 äº¿å‚æ•°ã€‚  \n",
    "ç»“åˆæ¨¡å‹é‡åŒ–æŠ€æœ¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§çš„æ˜¾å¡ä¸Šè¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼ˆINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½åªéœ€ 6GB æ˜¾å­˜ï¼‰ã€‚  \n",
    "ChatGLM-6B ä½¿ç”¨äº†å’Œ ChatGLM ç›¸åŒçš„æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸­æ–‡é—®ç­”å’Œå¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚  \n",
    "ç»è¿‡çº¦ 1T æ ‡è¯†ç¬¦çš„ä¸­è‹±åŒè¯­è®­ç»ƒï¼Œè¾…ä»¥ç›‘ç£å¾®è°ƒã€åé¦ˆè‡ªåŠ©ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯çš„åŠ æŒï¼Œ62 äº¿å‚æ•°çš„ ChatGLM-6B å·²ç»èƒ½ç”Ÿæˆç›¸å½“ç¬¦åˆäººç±»åå¥½çš„å›ç­”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823a00a06b6c45cc9db1b02bb7519d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True).half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7099b482f1474c44bf86edad5237bc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, Tuple, Union, Optional\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "def auto_configure_device_map(num_gpus: int) -> Dict[str, int]:\n",
    "    # transformer.word_embeddings å ç”¨1å±‚\n",
    "    # transformer.final_layernorm å’Œ lm_head å ç”¨1å±‚\n",
    "    # transformer.layers å ç”¨ 28 å±‚\n",
    "    # æ€»å…±30å±‚åˆ†é…åˆ°num_gpuså¼ å¡ä¸Š\n",
    "    num_trans_layers = 28\n",
    "    per_gpu_layers = 30 / num_gpus\n",
    "\n",
    "    # bugfix: åœ¨linuxä¸­è°ƒç”¨torch.embeddingä¼ å…¥çš„weight,inputä¸åœ¨åŒä¸€deviceä¸Š,å¯¼è‡´RuntimeError\n",
    "    # windowsä¸‹ model.device ä¼šè¢«è®¾ç½®æˆ transformer.word_embeddings.device\n",
    "    # linuxä¸‹ model.device ä¼šè¢«è®¾ç½®æˆ lm_head.device\n",
    "    # åœ¨è°ƒç”¨chatæˆ–è€…stream_chatæ—¶,input_idsä¼šè¢«æ”¾åˆ°model.deviceä¸Š\n",
    "    # å¦‚æœtransformer.word_embeddings.deviceå’Œmodel.deviceä¸åŒ,åˆ™ä¼šå¯¼è‡´RuntimeError\n",
    "    # å› æ­¤è¿™é‡Œå°†transformer.word_embeddings,transformer.final_layernorm,lm_headéƒ½æ”¾åˆ°ç¬¬ä¸€å¼ å¡ä¸Š\n",
    "    device_map = {'transformer.word_embeddings': 0,\n",
    "                  'transformer.final_layernorm': 0, \n",
    "                  'lm_head': 0}\n",
    "\n",
    "    used = 2\n",
    "    gpu_target = 0\n",
    "    for i in range(num_trans_layers):\n",
    "        if used >= per_gpu_layers:\n",
    "            gpu_target += 1\n",
    "            used = 0\n",
    "        assert gpu_target < num_gpus\n",
    "        device_map[f'transformer.layers.{i}'] = gpu_target\n",
    "        used += 1\n",
    "\n",
    "    return device_map\n",
    "\n",
    "def load_model_on_gpus(checkpoint_path: Union[str, os.PathLike], num_gpus: int = 2,\n",
    "                       device_map: Optional[Dict[str, int]] = None, **kwargs) -> Module:\n",
    "    if num_gpus < 2 and device_map is None:\n",
    "        model = AutoModel.from_pretrained(checkpoint_path, trust_remote_code=True, **kwargs).half().cuda()\n",
    "    else:\n",
    "        from accelerate import dispatch_model\n",
    "\n",
    "        model = AutoModel.from_pretrained(checkpoint_path, trust_remote_code=True, **kwargs).half()\n",
    "\n",
    "        if device_map is None:\n",
    "            device_map = auto_configure_device_map(num_gpus)\n",
    "\n",
    "        model = dispatch_model(model, device_map=device_map)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model_on_gpus(\"THUDM/chatglm-6b\", num_gpus=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dtype of attention mask (torch.int64) is not bool\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"ä½ å¥½\", history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"ç°åœ¨æ€ä¹ˆå…¥æ‰‹nlp?\", history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†(Natural Language Processing)çš„ç¼©å†™ï¼Œæ˜¯ä¸€ç§äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œæ—¨åœ¨ä½¿è®¡ç®—æœºç†è§£å’Œè§£é‡Šäººç±»è¯­è¨€ã€‚å¦‚æœæ‚¨æƒ³å…¥æ‰‹ NLPï¼Œä»¥ä¸‹æ˜¯ä¸€äº›æ­¥éª¤ï¼š\\n\\n1. å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†çš„åŸºç¡€çŸ¥è¯†ï¼šäº†è§£è‡ªç„¶è¯­è¨€å¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€æŠ€æœ¯å’Œåº”ç”¨ï¼Œä¾‹å¦‚æ–‡æœ¬é¢„å¤„ç†ã€æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æã€æœºå™¨ç¿»è¯‘ç­‰ã€‚\\n\\n2. æŒæ¡ç¼–ç¨‹æŠ€èƒ½ï¼šè‡ªç„¶è¯­è¨€å¤„ç†éœ€è¦ç¼–ç¨‹æŠ€èƒ½ï¼Œå› æ­¤æ‚¨éœ€è¦æŒæ¡è‡³å°‘ä¸€é—¨ç¼–ç¨‹è¯­è¨€ï¼Œä¾‹å¦‚ Pythonã€Java ç­‰ã€‚\\n\\n3. å­¦ä¹  NLP æ¡†æ¶ï¼šäº†è§£å¸¸ç”¨çš„è‡ªç„¶è¯­è¨€å¤„ç†æ¡†æ¶ï¼Œä¾‹å¦‚ NLTKã€ spaCyã€ Gensim ç­‰ã€‚\\n\\n4. å®è·µé¡¹ç›®ï¼šé€šè¿‡å®è·µé¡¹ç›®æ¥å·©å›ºæ‰€å­¦çŸ¥è¯†ï¼Œä¾‹å¦‚é€šè¿‡æ„å»ºä¸€ä¸ªç®€å•çš„æ–‡æœ¬åˆ†ç±»å™¨ã€æƒ…æ„Ÿåˆ†æç³»ç»Ÿç­‰ã€‚\\n\\n5. å‚åŠ åœ¨çº¿è¯¾ç¨‹æˆ–åŸ¹è®­ï¼šå‚åŠ åœ¨çº¿è¯¾ç¨‹æˆ–åŸ¹è®­å¯ä»¥ä¸ºæ‚¨æä¾›ä¸“ä¸šçš„æŒ‡å¯¼å’Œå­¦ä¹ èµ„æºï¼Œä¾‹å¦‚Courseraã€Udacityã€edXç­‰ã€‚\\n\\n6. åŠ å…¥ç¤¾åŒºï¼šåŠ å…¥è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³çš„ç¤¾åŒºå¯ä»¥ä¸ºæ‚¨æä¾›ä¸å…¶ä»–å­¦ä¹ è€…å’Œä¸“ä¸šäººå£«äº¤æµçš„æœºä¼šï¼Œä¾‹å¦‚ Stack Overflowã€GitHub ç­‰ã€‚\\n\\nå¸Œæœ›è¿™äº›æ­¥éª¤å¯ä»¥å¸®åŠ©æ‚¨å…¥é—¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€‚'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"æˆ‘æ¥è‡ªååŒ—ç”µåŠ›å¤§å­¦\", history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¾ˆé«˜å…´å¬åˆ°æ‚¨æ¥è‡ªååŒ—ç”µåŠ›å¤§å­¦ï¼ä½œä¸ºä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥å›ç­”æ‚¨çš„é—®é¢˜ï¼Œæä¾›å¸®åŠ©å’Œä¿¡æ¯ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶é—®æˆ‘ã€‚'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"æŒ‰ç…§æˆ‘ä¸Šé¢å‘Šè¯‰ä½ çš„ä¿¡æ¯ï¼Œæˆ‘æ¥è‡ªå“ªå„¿\", history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œæ‚¨æ¥è‡ªååŒ—ç”µåŠ›å¤§å­¦ã€‚ä½œä¸ºä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘æ— æ³•éªŒè¯æ‚¨æä¾›çš„ä¿¡æ¯çš„å‡†ç¡®æ€§ï¼Œä½†æˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶é—®æˆ‘ã€‚'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ç”µåŠ›ç³»ç»Ÿæ˜¯æŒ‡å°†ç”µèƒ½ä»å‘ç”µç«™ä¼ è¾“åˆ°ç”¨ç”µè®¾å¤‡çš„ç³»ç»Ÿï¼Œæ˜¯ç°ä»£ç¤¾ä¼šç”µåŠ›ä¾›åº”çš„åŸºç¡€ã€‚ä»¥ä¸‹æ˜¯ç”µåŠ›ç³»ç»Ÿçš„ä¸€äº›è¯„ä»·æ–¹é¢ï¼š\n",
       "\n",
       "1. å¯é æ€§ï¼šç”µåŠ›ç³»ç»Ÿçš„å¯é æ€§å¯¹äºç”µåŠ›ä¾›åº”çš„ç¨³å®šæ€§è‡³å…³é‡è¦ã€‚ç”µåŠ›ç³»ç»Ÿçš„è®¾è®¡å’Œè¿è¡Œéœ€è¦è€ƒè™‘åˆ°å„ç§å› ç´ ï¼Œå¦‚å‘ç”µç«™å’Œç”¨ç”µè®¾å¤‡çš„æ•…éšœç‡ã€ç”µåŠ›ä¼ è¾“çš„å»¶è¿Ÿå’Œä¸­æ–­ç­‰ï¼Œç¡®ä¿ç”µåŠ›ç³»ç»Ÿçš„å¯é è¿è¡Œã€‚\n",
       "\n",
       "2. æ•ˆç‡ï¼šç”µåŠ›ç³»ç»Ÿçš„æ•ˆç‡æŒ‡çš„æ˜¯å…¶èƒ½é‡åˆ©ç”¨æ•ˆç‡ï¼Œå³ç”µåŠ›ç³»ç»Ÿå°†èƒ½é‡ä»å‘ç”µç«™ä¼ è¾“åˆ°ç”¨ç”µè®¾å¤‡çš„æ•ˆç‡ã€‚é«˜æ•ˆçš„ç”µåŠ›ç³»ç»Ÿå¯ä»¥å‡å°‘èƒ½æºæµªè´¹å’ŒæŸå¤±ï¼Œæé«˜èƒ½æºåˆ©ç”¨æ•ˆç‡ã€‚\n",
       "\n",
       "3. å¯æŒç»­æ€§ï¼šç”µåŠ›ç³»ç»Ÿçš„å¯æŒç»­æ€§éœ€è¦è€ƒè™‘å…¶ç¯å¢ƒå½±å“å’Œèµ„æºåˆ©ç”¨ã€‚ç°ä»£ç”µåŠ›ç³»ç»Ÿé€šå¸¸é‡‡ç”¨å¯å†ç”Ÿèƒ½æºå‘ç”µï¼Œä»¥å‡å°‘å¯¹åŒ–çŸ³ç‡ƒæ–™çš„ä¾èµ–å’Œå¯¹ç¯å¢ƒçš„æ±¡æŸ“ã€‚åŒæ—¶ï¼Œç”µåŠ›ç³»ç»Ÿçš„å¯æŒç»­æ€§è¿˜è€ƒè™‘å…¶èƒ½æºæ¶ˆè€—å’Œèƒ½æºå‚¨å­˜çš„å¯æŒç»­æ€§ã€‚\n",
       "\n",
       "4. å®‰å…¨æ€§ï¼šç”µåŠ›ç³»ç»Ÿçš„å®‰å…¨æ€§åŒ…æ‹¬å„ç§å®‰å…¨æªæ–½ï¼Œå¦‚ç”µåŠ›ä¿éšœã€äººå‘˜å®‰å…¨ã€è®¾å¤‡ä¿æŠ¤ç­‰ï¼Œä»¥ç¡®ä¿ç”µåŠ›ç³»ç»Ÿçš„æ­£å¸¸è¿è¡Œå’Œå®‰å…¨è¿è¡Œã€‚\n",
       "\n",
       "5. æˆæœ¬æ•ˆç›Šï¼šç”µåŠ›ç³»ç»Ÿçš„æˆæœ¬æ•ˆç›Šéœ€è¦è€ƒè™‘å…¶ç»æµæ•ˆç›Šï¼Œå³ç”µåŠ›ç³»ç»Ÿçš„èƒ½æºæˆæœ¬ã€å»ºè®¾æˆæœ¬ã€è¿è¥æˆæœ¬ç­‰ä¸èƒ½æºä»·æ ¼çš„å…³ç³»ã€‚é«˜èƒ½æºä»·æ ¼å¯èƒ½å¯¼è‡´ç”µåŠ›ç³»ç»Ÿæˆæœ¬ä¸Šå‡ï¼Œä½†ä½èƒ½æºä»·æ ¼åˆ™å¯èƒ½å¯¼è‡´ç”µåŠ›ç³»ç»Ÿæˆæœ¬ä¸‹é™ã€‚\n",
       "\n",
       "ç”µåŠ›ç³»ç»Ÿæ˜¯ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿï¼Œéœ€è¦è€ƒè™‘å¤šä¸ªæ–¹é¢çš„è¯„ä»·ï¼ŒåŒ…æ‹¬å¯é æ€§ã€æ•ˆç‡ã€å¯æŒç»­æ€§ã€å®‰å…¨æ€§å’Œæˆæœ¬æ•ˆç›Šç­‰ã€‚"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "prompt = \"ä»å¤šæ–¹é¢è¯„ä»·ç”µåŠ›ç³»ç»Ÿ\"\n",
    "for response, history in model.stream_chat(\n",
    "        tokenizer, prompt, history=[]):\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb35025f1104b43aec35c358ec0a421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add670512a3847b8beafb1e7aa9e487f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260c664749754c5d899c0ff479aa8be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fdfb5a6af4483f8deb0eaa1cacbfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

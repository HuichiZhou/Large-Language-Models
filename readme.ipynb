{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成instruct指令数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "正克隆到 'stanford_alpaca'...\n",
      "remote: Enumerating objects: 129, done.\u001b[K\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 129 (delta 55), reused 52 (delta 50), pack-reused 56\u001b[K\n",
      "接收对象中: 100% (129/129), 9.15 MiB | 2.67 MiB/s, done.\n",
      "处理 delta 中: 100% (61/61), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tatsu-lab/stanford_alpaca.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/zhc/llm/My_ChatGLM_6B_Lora_Tuning_En_And_Zh/stanford_alpaca\n"
     ]
    }
   ],
   "source": [
    "%cd stanford_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: numpy in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.25.0)\n",
      "Collecting rouge_score (from -r requirements.txt (line 2))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fire (from -r requirements.txt (line 3))\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m483.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: openai in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.27.8)\n",
      "Requirement already satisfied: transformers>=4.28.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (4.30.2)\n",
      "Requirement already satisfied: torch in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: sentencepiece in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.1.99)\n",
      "Requirement already satisfied: tokenizers>=0.13.3 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.13.3)\n",
      "Collecting wandb (from -r requirements.txt (line 9))\n",
      "  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.4.0)\n",
      "Collecting nltk (from rouge_score->-r requirements.txt (line 2))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.16.0)\n",
      "Collecting termcolor (from fire->-r requirements.txt (line 3))\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from openai->-r requirements.txt (line 4)) (3.8.4)\n",
      "Requirement already satisfied: filelock in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from transformers>=4.28.1->-r requirements.txt (line 5)) (0.3.1)\n",
      "Requirement already satisfied: typing-extensions in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (4.6.3)\n",
      "Requirement already satisfied: sympy in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: networkx in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from torch->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 6)) (67.8.0)\n",
      "Requirement already satisfied: wheel in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 6)) (0.38.4)\n",
      "Requirement already satisfied: cmake in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 6)) (3.26.4)\n",
      "Requirement already satisfied: lit in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 6)) (16.0.6)\n",
      "Collecting Click!=8.0.0,>=7.0 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading sentry_sdk-1.26.0-py2.py3-none-any.whl (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb->-r requirements.txt (line 9))\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 9)) (4.23.3)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9))\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.28.1->-r requirements.txt (line 5)) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 6)) (2.1.3)\n",
      "Collecting joblib (from nltk->rouge_score->-r requirements.txt (line 2))\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /root/anaconda3/envs/llm/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 6)) (1.3.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9))\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: rouge_score, fire, pathtools\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=ba2a6d0803fdfe52549029545a9ccee48f5bb5bdc40515c9fc39c583c5d1ab92\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116931 sha256=4ef0f7b0136bfc934c2d811361d25bb91629cd4cfdc8a8d9ae6f8fb66f95933e\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=dc06f4eaa8b52c55997f1e54717e580cae1b56fac9f0833bcdb2915b122c6deb\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "Successfully built rouge_score fire pathtools\n",
      "Installing collected packages: pathtools, appdirs, termcolor, smmap, setproctitle, sentry-sdk, joblib, docker-pycreds, Click, nltk, gitdb, fire, rouge_score, GitPython, wandb\n",
      "Successfully installed Click-8.1.3 GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 fire-0.5.0 gitdb-4.0.10 joblib-1.2.0 nltk-3.8.1 pathtools-0.1.2 rouge_score-0.1.2 sentry-sdk-1.26.0 setproctitle-1.3.2 smmap-5.0.0 termcolor-2.3.0 wandb-0.15.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai \n",
    "openai.api_key = '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'\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/zhc/stanford_alpaca\n"
     ]
    }
   ],
   "source": [
    "%cd /root/zhc/stanford_alpaca"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以上加载完openai_key， 以下开始进行正式操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json \n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import tqdm \n",
    "from rouge_score import rouge_scorer\n",
    "import utils \n",
    "\n",
    "import fire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_prompt(prompt_instructions):\n",
    "    \"\"\"Encode multiple prompt instructions into a single string.\"\"\"\n",
    "    prompt = open(\"./prompt.txt\").read() + \"\\n\"\n",
    "\n",
    "    for idx, task_dict in enumerate(prompt_instructions):\n",
    "        (instruction, input, output) = task_dict[\"instruction\"], task_dict[\"input\"], task_dict[\"output\"]\n",
    "        instruction = re.sub(r\"\\s+\", \" \", instruction).strip().rstrip(\":\")\n",
    "        input = \"<noinput>\" if input.lower() == \"\" else input\n",
    "        prompt += f\"###\\n\"\n",
    "        prompt += f\"{idx + 1}. Instruction: {instruction}\\n\"\n",
    "        prompt += f\"{idx + 1}. Input:\\n{input}\\n\"\n",
    "        prompt += f\"{idx + 1}. Output:\\n{output}\\n\"\n",
    "    prompt += f\"###\\n\"\n",
    "    prompt += f\"{idx + 2}. Instruction:\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def post_process_gpt3_response(num_prompt_instructions, response):\n",
    "    if response is None:\n",
    "        return []\n",
    "    raw_instructions = f\"{num_prompt_instructions+1}. Instruction:\" + response[\"text\"]\n",
    "    raw_instructions = re.split(\"###\", raw_instructions)\n",
    "    instructions = []\n",
    "    for idx, inst in enumerate(raw_instructions):\n",
    "        # if the decoding stops due to length, the last example is likely truncated so we discard it\n",
    "        if idx == len(raw_instructions) - 1 and response[\"finish_reason\"] == \"length\":\n",
    "            continue\n",
    "        idx += num_prompt_instructions + 1\n",
    "        splitted_data = re.split(f\"{idx}\\.\\s+(Instruction|Input|Output):\", inst)\n",
    "        if len(splitted_data) != 7:\n",
    "            continue\n",
    "        else:\n",
    "            inst = splitted_data[2].strip()\n",
    "            input = splitted_data[4].strip()\n",
    "            input = \"\" if input.lower() == \"<noinput>\" else input\n",
    "            output = splitted_data[6].strip()\n",
    "        # filter out too short or too long instructions\n",
    "        if len(inst.split()) <= 3 or len(inst.split()) > 150:\n",
    "            continue\n",
    "        # filter based on keywords that are not suitable for language models.\n",
    "        blacklist = [\n",
    "            \"image\",\n",
    "            \"images\",\n",
    "            \"graph\",\n",
    "            \"graphs\",\n",
    "            \"picture\",\n",
    "            \"pictures\",\n",
    "            \"file\",\n",
    "            \"files\",\n",
    "            \"map\",\n",
    "            \"maps\",\n",
    "            \"draw\",\n",
    "            \"plot\",\n",
    "            \"go to\",\n",
    "            \"video\",\n",
    "            \"audio\",\n",
    "            \"music\",\n",
    "            \"flowchart\",\n",
    "            \"diagram\",\n",
    "        ]\n",
    "        blacklist += []\n",
    "        if any(find_word_in_string(word, inst) for word in blacklist):\n",
    "            continue\n",
    "        # We found that the model tends to add \"write a program\" to some existing instructions, which lead to a lot of such instructions.\n",
    "        # And it's a bit comfusing whether the model need to write a program or directly output the result.\n",
    "        # Here we filter them out.\n",
    "        # Note this is not a comprehensive filtering for all programming instructions.\n",
    "        if inst.startswith(\"Write a program\"):\n",
    "            continue\n",
    "        # filter those starting with punctuation\n",
    "        if inst[0] in string.punctuation:\n",
    "            continue\n",
    "        # filter those starting with non-english character\n",
    "        if not inst[0].isascii():\n",
    "            continue\n",
    "        instructions.append({\"instruction\": inst, \"input\": input, \"output\": output})\n",
    "    return instructions\n",
    "\n",
    "\n",
    "def find_word_in_string(w, s):\n",
    "    return re.compile(r\"\\b({0})\\b\".format(w), flags=re.IGNORECASE).search(s)\n",
    "\n",
    "\n",
    "def generate_instruction_following_data(\n",
    "    output_dir=\"./\",\n",
    "    seed_tasks_path=\"./seed_tasks.jsonl\",\n",
    "    num_instructions_to_generate=100,\n",
    "    model_name=\"text-davinci-003\",\n",
    "    num_prompt_instructions=3,\n",
    "    request_batch_size=5,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    num_cpus=16,\n",
    "):\n",
    "    seed_tasks = [json.loads(l) for l in open(seed_tasks_path, \"r\")]\n",
    "    seed_instruction_data = [\n",
    "        {\"instruction\": t[\"instruction\"], \"input\": t[\"instances\"][0][\"input\"], \"output\": t[\"instances\"][0][\"output\"]}\n",
    "        for t in seed_tasks\n",
    "    ]\n",
    "    print(f\"Loaded {len(seed_instruction_data)} human-written seed instructions\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    request_idx = 0\n",
    "    # load the LM-generated instructions\n",
    "    machine_instruction_data = []\n",
    "    if os.path.exists(os.path.join(output_dir, \"regen.json\")):\n",
    "        machine_instruction_data = utils.jload(os.path.join(output_dir, \"regen.json\"))\n",
    "        print(f\"Loaded {len(machine_instruction_data)} machine-generated instructions\")\n",
    "\n",
    "    # similarities = {}\n",
    "    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=False)\n",
    "\n",
    "    # now let's generate new instructions!\n",
    "    progress_bar = tqdm.tqdm(total=num_instructions_to_generate)\n",
    "    if machine_instruction_data:\n",
    "        progress_bar.update(len(machine_instruction_data))\n",
    "\n",
    "    # first we tokenize all the seed instructions and generated machine instructions\n",
    "    all_instructions = [d[\"instruction\"] for d in seed_instruction_data] + [\n",
    "        d[\"instruction\"] for d in machine_instruction_data\n",
    "    ]\n",
    "    all_instruction_tokens = [scorer._tokenizer.tokenize(inst) for inst in all_instructions]\n",
    "\n",
    "    while len(machine_instruction_data) < num_instructions_to_generate:\n",
    "        request_idx += 1\n",
    "\n",
    "        batch_inputs = []\n",
    "        for _ in range(request_batch_size):\n",
    "            # only sampling from the seed tasks\n",
    "            prompt_instructions = random.sample(seed_instruction_data, num_prompt_instructions)\n",
    "            prompt = encode_prompt(prompt_instructions)\n",
    "            batch_inputs.append(prompt)\n",
    "        decoding_args = utils.OpenAIDecodingArguments(\n",
    "            temperature=temperature,\n",
    "            n=1,\n",
    "            max_tokens=3072,  # hard-code to maximize the length. the requests will be automatically adjusted\n",
    "            top_p=top_p,\n",
    "            stop=[\"\\n20\", \"20.\", \"20.\"],\n",
    "        )\n",
    "        request_start = time.time()\n",
    "        results = utils.openai_completion(\n",
    "            prompts=batch_inputs,\n",
    "            model_name=model_name,\n",
    "            batch_size=request_batch_size,\n",
    "            decoding_args=decoding_args,\n",
    "            logit_bias={\"50256\": -100},  # prevent the <|endoftext|> token from being generated\n",
    "        )\n",
    "        request_duration = time.time() - request_start\n",
    "\n",
    "        process_start = time.time()\n",
    "        instruction_data = []\n",
    "        for result in results:\n",
    "            new_instructions = post_process_gpt3_response(num_prompt_instructions, result)\n",
    "            instruction_data += new_instructions\n",
    "\n",
    "        total = len(instruction_data)\n",
    "        keep = 0\n",
    "        for instruction_data_entry in instruction_data:\n",
    "            # computing similarity with the pre-tokenzied instructions\n",
    "            new_instruction_tokens = scorer._tokenizer.tokenize(instruction_data_entry[\"instruction\"])\n",
    "            with Pool(num_cpus) as p:\n",
    "                rouge_scores = p.map(\n",
    "                    partial(rouge_scorer._score_lcs, new_instruction_tokens),\n",
    "                    all_instruction_tokens,\n",
    "                )\n",
    "            rouge_scores = [score.fmeasure for score in rouge_scores]\n",
    "            most_similar_instructions = {\n",
    "                all_instructions[i]: rouge_scores[i] for i in np.argsort(rouge_scores)[-10:][::-1]\n",
    "            }\n",
    "            if max(rouge_scores) > 0.7:\n",
    "                continue\n",
    "            else:\n",
    "                keep += 1\n",
    "            instruction_data_entry[\"most_similar_instructions\"] = most_similar_instructions\n",
    "            instruction_data_entry[\"avg_similarity_score\"] = float(np.mean(rouge_scores))\n",
    "            machine_instruction_data.append(instruction_data_entry)\n",
    "            all_instructions.append(instruction_data_entry[\"instruction\"])\n",
    "            all_instruction_tokens.append(new_instruction_tokens)\n",
    "            progress_bar.update(1)\n",
    "        process_duration = time.time() - process_start\n",
    "        print(f\"Request {request_idx} took {request_duration:.2f}s, processing took {process_duration:.2f}s\")\n",
    "        print(f\"Generated {total} instructions, kept {keep} instructions\")\n",
    "        utils.jdump(machine_instruction_data, os.path.join(output_dir, \"regen.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Write a short story in third person narration about a protagonist who has to make an important career decision.',\n",
       " 'input': '',\n",
       " 'output': 'John was at a crossroads in his life. He had just graduated college and was now facing the big decision of what career to pursue. After much deliberation, he decided that he wanted to be an accountant and help the financially disadvantaged. He had always been good with numbers and enjoyed seeing the tangible results of his work. \\n\\nJohn enrolled in accounting courses and initially found it quite challenging. He had to learn multiple systems and regulations quickly, but he worked hard and eventually excelled in his studies. After a few years, John started working at an accounting firm in his city. He was eager to put his knowledge of taxes and accounting to use in a real-world setting.\\n\\nJohn loved his job, as it let him express his creativity in finding strategies to save his clients money. After a few years at the firm, he became a senior accountant and was asked to manage bigger and more challenging cases. He was now a respected figure in the financial industry, but he still remembers when he was just a recent college graduate, unsure of the direction in which his life would take him.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"alpaca_data.json\"\n",
    "\n",
    "with open(file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# print(data)\n",
    "data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 175 human-written seed instructions\n"
     ]
    }
   ],
   "source": [
    "seed_tasks_path=\"./seed_tasks.jsonl\"\n",
    "\n",
    "seed_tasks = [json.loads(l) for l in open(seed_tasks_path, \"r\")]\n",
    "\n",
    "seed_instruction_data = [\n",
    "    {\"instruction\": t[\"instruction\"], \n",
    "     \"input\": t[\"instances\"][0][\"input\"], \n",
    "     \"output\": t[\"instances\"][0][\"output\"]}\n",
    "     \n",
    "    for t in seed_tasks\n",
    "]\n",
    "print(f\"Loaded {len(seed_instruction_data)} human-written seed instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'seed_task_7',\n",
       " 'name': 'idiom_meaning',\n",
       " 'instruction': 'Explain the following idiom to me, and try to give me some examples.',\n",
       " 'instances': [{'input': 'black sheep',\n",
       "   'output': 'Meaning: An outcast. Someone who doesn’t fit in with the rest of the crowd. They take pride in being different. Thinks for themselves and doesn’t care what no one else has to say. They tend to ride their own wave and are usually loners because no one understands them, but its okay because they like it that way.\\nExample: He’s the black sheep of the family.'}],\n",
       " 'is_classification': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_tasks[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seed_tasks = seed_tasks[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'seed_task_0',\n",
       "  'name': 'breakfast_suggestion',\n",
       "  'instruction': \"Is there anything I can eat for a breakfast that doesn't include eggs, yet includes protein, and has roughly 700-1000 calories?\",\n",
       "  'instances': [{'input': '',\n",
       "    'output': 'Yes, you can have 1 oatmeal banana protein shake and 4 strips of bacon. The oatmeal banana protein shake may contain 1/2 cup oatmeal, 60 grams whey protein powder, 1/2 medium banana, 1tbsp flaxseed oil and 1/2 cup watter, totalling about 550 calories. The 4 strips of bacon contains about 200 calories.'}],\n",
       "  'is_classification': False},\n",
       " {'id': 'seed_task_1',\n",
       "  'name': 'antonym_relation',\n",
       "  'instruction': 'What is the relation between the given pairs?',\n",
       "  'instances': [{'input': 'Night : Day :: Right : Left',\n",
       "    'output': 'The relation between the given pairs is that they are opposites.'}],\n",
       "  'is_classification': False},\n",
       " {'id': 'seed_task_2',\n",
       "  'name': 'one_sentence_description',\n",
       "  'instruction': 'Generate a one-sentence description for each of the following people.',\n",
       "  'instances': [{'input': '- Brack Obama\\n- Elon Musk\\n- Taylor Swift',\n",
       "    'output': '- Barack Hussein Obama II is an American politician who served as the 44th president of the United States from 2009 to 2017.\\n- Elon Musk is the founder, CEO, and chief engineer of SpaceX; angel investor, CEO and product architect of Tesla, Inc.; founder of The Boring Company; co-founder of Neuralink and OpenAI; president of the Musk Foundation; and owner and CEO of Twitter, Inc.\\n- Taylor Alison Swift is an American singer-songwriter.'}],\n",
       "  'is_classification': False}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_seed_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_new_tasks = '''\n",
    "[\n",
    "    {\n",
    "        \"id\": \"new_seed_task_3\",\n",
    "        \"name\": \"vegetarian_dinner_options\",\n",
    "        \"instruction\": \"What are some vegetarian dinner options with high protein content?\",\n",
    "        \"instances\": [{\"input\": \"\",\n",
    "                      \"output\": \"Some vegetarian dinner options with high protein content include lentil soup, chickpea curry, tofu stir-fry, tempeh tacos, and quinoa stuffed peppers.\"}],\n",
    "        \"is_classification\": false\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"new_seed_task_4\",\n",
    "        \"name\": \"refund_policy_explanation\",\n",
    "        \"instruction\": \"Can you explain your refund policy?\",\n",
    "        \"instances\": [{\"input\": \"\",\n",
    "                      \"output\": \"Our refund policy allows customers to request a refund within 30 days of purchase if they are unsatisfied with the product or service. To be eligible for a refund, the product must be in its original condition and packaging, and services must not have been completed.\"}],\n",
    "        \"is_classification\": false\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"new_seed_task_5\",\n",
    "        \"name\": \"troubleshoot_wifi_connection\",\n",
    "        \"instruction\": \"I'm having trouble connecting to my Wi-Fi network. What should I do?\",\n",
    "        \"instances\": [{\"input\": \"\",\n",
    "                      \"output\": \"First, check if your device is within range of your Wi-Fi router. Then, verify that you have entered the correct network name and password. If the issue persists, try restarting both your device and the router. If you still cannot connect, contact your internet service provider for further assistance.\"}],\n",
    "        \"is_classification\": false\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"new_seed_task_6\",\n",
    "        \"name\": \"change_password_instructions\",\n",
    "        \"instruction\": \"How do I change my password?\",\n",
    "        \"instances\": [{\"input\": \"\",\n",
    "                      \"output\": \"To change your password, log in to your account, go to the settings or account management section, and find the option to change your password. Enter your current password, then enter your new password twice for confirmation. Save your changes to update your password.\"}],\n",
    "        \"is_classification\": false\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"new_seed_task_7\",\n",
    "        \"name\": \"lost_package_inquiry\",\n",
    "        \"instruction\": \"My package hasn't arrived yet. What should I do?\",\n",
    "        \"instances\": [{\"input\": \"\",\n",
    "                      \"output\": \"First, check your order confirmation email or account for the tracking number and delivery date estimate. If the delivery date has passed, contact the shipping carrier with your tracking number for an update. If the carrier cannot resolve the issue, please contact our customer support team for assistance.\"}],\n",
    "        \"is_classification\": false\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"new_seed_task_8\",\n",
    "        \"name\": \"modify_order\",\n",
    "        \"instruction\": \"I need to modify my order. How can I do that?\",\n",
    "        \"instances\": [{\"input\": \"\",\n",
    "                      \"output\": \"To modify your order, please contact our customer support team as soon as possible with your order number and the changes you would like to make. Please note that modifications may not be possible if the order has already been processed or shipped.\"}],\n",
    "        \"is_classification\": false\n",
    "    }\n",
    "]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'new_seed_task_3', 'name': 'vegetarian_dinner_options', 'instruction': 'What are some vegetarian dinner options with high protein content?', 'instances': [{'input': '', 'output': 'Some vegetarian dinner options with high protein content include lentil soup, chickpea curry, tofu stir-fry, tempeh tacos, and quinoa stuffed peppers.'}], 'is_classification': False}, {'id': 'new_seed_task_4', 'name': 'refund_policy_explanation', 'instruction': 'Can you explain your refund policy?', 'instances': [{'input': '', 'output': 'Our refund policy allows customers to request a refund within 30 days of purchase if they are unsatisfied with the product or service. To be eligible for a refund, the product must be in its original condition and packaging, and services must not have been completed.'}], 'is_classification': False}, {'id': 'new_seed_task_5', 'name': 'troubleshoot_wifi_connection', 'instruction': \"I'm having trouble connecting to my Wi-Fi network. What should I do?\", 'instances': [{'input': '', 'output': 'First, check if your device is within range of your Wi-Fi router. Then, verify that you have entered the correct network name and password. If the issue persists, try restarting both your device and the router. If you still cannot connect, contact your internet service provider for further assistance.'}], 'is_classification': False}, {'id': 'new_seed_task_6', 'name': 'change_password_instructions', 'instruction': 'How do I change my password?', 'instances': [{'input': '', 'output': 'To change your password, log in to your account, go to the settings or account management section, and find the option to change your password. Enter your current password, then enter your new password twice for confirmation. Save your changes to update your password.'}], 'is_classification': False}, {'id': 'new_seed_task_7', 'name': 'lost_package_inquiry', 'instruction': \"My package hasn't arrived yet. What should I do?\", 'instances': [{'input': '', 'output': 'First, check your order confirmation email or account for the tracking number and delivery date estimate. If the delivery date has passed, contact the shipping carrier with your tracking number for an update. If the carrier cannot resolve the issue, please contact our customer support team for assistance.'}], 'is_classification': False}, {'id': 'new_seed_task_8', 'name': 'modify_order', 'instruction': 'I need to modify my order. How can I do that?', 'instances': [{'input': '', 'output': 'To modify your order, please contact our customer support team as soon as possible with your order number and the changes you would like to make. Please note that modifications may not be possible if the order has already been processed or shipped.'}], 'is_classification': False}]\n"
     ]
    }
   ],
   "source": [
    "new_seed_tasks = json.loads(json_new_tasks)\n",
    "print(new_seed_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_seed_tasks.jsonl', 'w') as outfile:\n",
    "    for task_dict in new_seed_tasks:\n",
    "        json.dump(task_dict, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: 无法创建目录\"new_tasks\": 文件已存在\n"
     ]
    }
   ],
   "source": [
    "!mkdir new_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 human-written seed instructions\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\n",
      "prompt_batches:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████████| 1/1 [00:36<00:00, 36.42s/it]\u001b[A\n",
      "27it [00:37,  2.34it/s]Request 1 took 36.42s, processing took 0.61s             \n",
      "Generated 29 instructions, kept 28 instructions\n",
      "28it [00:37,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m generate_instruction generate_instruction_following_data \\\n",
    "    --output_dir ./new_tasks/ \\\n",
    "    --seed_tasks_path ./new_seed_tasks.jsonl \\\n",
    "    --num_instructions_to_generate 5 \\\n",
    "    --num_prompt_instructions 3 \\\n",
    "    --request_batch_size 2 \\\n",
    "    --num_cpus 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'instruction': 'What is the latest version of Windows?', 'input': '', 'output': 'The latest version of Windows is Windows 10, which was released in 2015. It is an operating system that is developed and maintained by Microsoft.'}, {'instruction': 'What is the average temperature in New York City?', 'input': '', 'output': 'The average temperature in New York City is approximately 52°F (11°C). The temperatures in the city can vary greatly throughout the year, with the highest recorded temperature at 100°F (38°C) in July and the lowest recorded at -15°F (-26°C) in January.'}, {'instruction': 'How much protein should I intake in a day?', 'input': '', 'output': 'The recommended daily allowance (RDA) of protein for an adult is 0.8 grams of protein per kilogram of body weight. For example, a woman who weighs 60 kg should consume 48 grams of protein a day. It is important to note that individual needs may vary depending on activity level, health status, and other factors.'}, {'instruction': 'How can I make potatoes healthier?', 'input': '', 'output': 'Potatoes can be made healthier by roasting or baking them instead of frying them. You can also add healthier toppings such as steamed vegetables, low-fat cheese, and beans. Additionally, you can limit your portion size and try using sweet potatoes instead of regular potatoes for added nutrition.'}, {'instruction': 'How do I delete an app from my phone?', 'input': '', 'output': 'To delete an app from your phone, open the Settings app on your device and tap on Applications or Apps. You should then see a list of all the apps installed on your phone. Tap on the app you want to delete and select the Uninstall option. Confirm your selection and the app will be deleted.'}, {'instruction': 'How can I use Google Docs?', 'input': '', 'output': 'Google Docs is a cloud-based word processor that allows you to create and collaborate on documents. It has a variety of features such as text formatting, inserting images, sharing documents, and commenting. To access Google Docs, you need to log into your Google Account and select the Google Docs icon. Once logged in, you can create a new document or upload an existing file.'}, {'instruction': 'What is the temperature of boiling water?', 'input': '', 'output': 'The temperature of boiling water is 212° Fahrenheit (100° Celsius). This is the temperature at sea level. At higher elevations, the boiling temperature of water decreases due to lower atmospheric pressure.'}, {'instruction': 'How do I set a reminder?', 'input': '', 'output': 'Reminders can be set using a number of different apps and devices, such as on a computer or smartphone. To set a reminder, launch the app, select the option to set a reminder, enter information about the reminder (date, time, and content), and save it.'}, {'instruction': 'What is the capital of France?', 'input': '', 'output': 'The capital of France is Paris. It is the most populous city in the country, located in the north-central part of the country on the banks of the River Seine.'}, {'instruction': 'How do I make a web page?', 'input': '', 'output': 'Making a web page is fairly straightforward with HTML and CSS. HTML (HyperText Markup Language) is the language used to create the content on the page and CSS (Cascading Style Sheets) is used to add styling and formatting. You can use an HTML editor and a web browser to code and preview your web page.'}, {'instruction': 'How can I reset my password?', 'input': '', 'output': \"To reset your password, go to the login page and select the option to 'forgot password'. Enter the email address associated with your account and you will receive an email with instructions on how to reset your password. Follow the steps provided and create a new password.\"}, {'instruction': 'What is a stock?', 'input': '', 'output': \"A stock is a security that represents an ownership stake in a company. Companies offer stocks to the public to raise capital and as an investment option for individuals. When people invest in stocks, they become shareholders and are entitled to a portion of the company's profits.\"}, {'instruction': 'How can I learn programming?', 'input': '', 'output': 'Learning programming can be done through self-teaching and taking courses. There are many online tutorials and courses available that cover the basics of programming as well as more advanced topics. For more hands-on practice, taking part in a computer science or coding bootcamp is a great way to get experience with programming.'}, {'instruction': 'Generate a random password of 8 characters.', 'input': '', 'output': 'kd2nef5h'}, {'instruction': 'What is the population of India in 2020?', 'input': '', 'output': 'According to the World Bank, the population of India in 2020 was 1.4 billion.'}, {'instruction': 'Analyze the following text and give three key insights.', 'input': \"The world's most successful companies have one thing in common - great customer service.\", 'output': \"1. World's most successful companies prioritize customer service. \\n2. Creating a great customer service experience can increase company success. \\n3. Providing excellent customer service is an essential part of doing business.\"}, {'instruction': \"I'm trying to decide between two mobile phones. What are the pros and cons of each?\", 'input': 'iPhone 7 and Samsung Galaxy S10', 'output': 'The iPhone 7 has a longer battery life, a smaller form factor, and a more simplistic design. However, it does not have the same level of features and performance as the Samsung Galaxy S10. The S10 has a larger, higher resolution display, a faster processor, expandable storage, and a more advanced camera system. However, it is also more expensive and more prone to heating up while heavy activities are being done.'}, {'instruction': 'How can I improve my search engine ranking?', 'input': '', 'output': 'To improve your search engine ranking, ensure that your website has high-quality content that is relevant to your audience, optimize your existing content with relevant keywords, and acquire links from authoritative websites in your industry. Additionally, you should regularly update your website with fresh content and use analytics tools to analyze the performance of your website.'}, {'instruction': 'Tell me about the latest trends in artificial intelligence.', 'input': '', 'output': 'Recently, artificial intelligence (AI) has seen major development and innovation in areas such as natural language processing (NLP), computer vision, and machine learning (ML). In particular, NLP has seen the emergence of powerful new AI tools to process and understand complex human language. Computer vision is seeing advancements in areas such as facial recognition, object detection, and image classification. ML is also rapidly evolving to address challenging problems such as predicting market trends and optimising decision making.'}, {'instruction': 'Write a marketing email praising our product.', 'input': '', 'output': 'At [Insert company name], we are proud to present our newest product, [Insert product name], a revolutionary solution that will revolutionize [Insert areas of use]. Our product offers unmatched [Insert features] and is designed to provide the best user experience. With our product, you can [Insert unique advantages], and make [Insert tasks] easier and more efficient. We invite you to explore [Insert product name] and experience the wonders it can bring to your day-to-day life.'}, {'instruction': 'Tell me a fun fact about cats.', 'input': '', 'output': \"Cats have an extra organ that allows them to taste scents in the air. This organ, called the Jacobson's organ, is located in the roof of their mouth and helps cats detect pheromones which aids in their hunting.\"}, {'instruction': 'Summarize the following article in 5 sentences.', 'input': 'The article is titled \"The Benefits of Exercise and Eating Healthy\"', 'output': 'Exercising regularly and eating a nutritious diet have a myriad of benefits for physical and mental health. Exercise can boost energy, build muscle, burn fat, and improve cardiovascular health. Eating a balanced and nutritious diet can help to limit the risk of chronic diseases, including heart disease and diabetes. A healthy diet also helps maintain a healthy weight. Additionally, both exercise and a healthy diet can help improve your mood, boost your energy levels, and contribute to overall physical and mental wellbeing.'}, {'instruction': 'I want to buy a new laptop. What options do I have?', 'input': '', 'output': 'When purchasing a new laptop, there are a lot of things to consider, including size, portability, processor speed, RAM, storage, graphics, battery life, and price. Depending on your needs, you may want to consider different laptop models from different manufacturers such as Dell, HP, Lenovo, Asus, and more. Additionally, there are a range of different types of laptops, including ultrabooks, gaming laptops, Chromebooks, and more.'}, {'instruction': 'Find the most common word in the following text.', 'input': 'The cat was sleeping soundly on the windowsill', 'output': 'The most common word in the text is \"the\" which appears 3 times.'}, {'instruction': 'Convert the following text from lowercase to uppercase.', 'input': 'the cat was sleeping soundly on the windowsill', 'output': 'THE CAT WAS SLEEPING SOUNDLY ON THE WINDOWSILL'}, {'instruction': 'What does the abbreviation SEO stand for?', 'input': '', 'output': 'SEO stands for Search Engine Optimization, which is the process of optimizing your website to increase its visibility in search engine results.'}, {'instruction': 'Rewrite the following sentence using active voice.', 'input': 'The tree was planted by him.', 'output': 'He planted the tree.'}, {'instruction': 'Name three search engine optimization techniques.', 'input': '', 'output': 'Three techniques for search engine optimization are on-page optimization, off-page optimization, and technical SEO. On-page optimization involves optimizing the content and structure of your website to make it more visible to search engine crawlers. Off-page optimization consists of building links from other websites to your own, and technical SEO involves optimizing the underlying technology of your website to ensure it is properly indexed by search engines.'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"./new_tasks/regen.json\"\n",
    "\n",
    "with open(file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# drop the most similar as measured by Rouge\n",
    "for dictionary in data:\n",
    "    dictionary.pop('most_similar_instructions', None)\n",
    "    dictionary.pop('avg_similarity_score',None)\n",
    "\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"I'm trying to decide between two mobile phones. What are the pros and cons of each?\",\n",
       " 'input': 'iPhone 7 and Samsung Galaxy S10',\n",
       " 'output': 'The iPhone 7 has a longer battery life, a smaller form factor, and a more simplistic design. However, it does not have the same level of features and performance as the Samsung Galaxy S10. The S10 has a larger, higher resolution display, a faster processor, expandable storage, and a more advanced camera system. However, it is also more expensive and more prone to heating up while heavy activities are being done.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'How can I make potatoes healthier?',\n",
       " 'input': '',\n",
       " 'output': 'Potatoes can be made healthier by roasting or baking them instead of frying them. You can also add healthier toppings such as steamed vegetables, low-fat cheese, and beans. Additionally, you can limit your portion size and try using sweet potatoes instead of regular potatoes for added nutrition.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Name three search engine optimization techniques.',\n",
       " 'input': '',\n",
       " 'output': 'Three techniques for search engine optimization are on-page optimization, off-page optimization, and technical SEO. On-page optimization involves optimizing the content and structure of your website to make it more visible to search engine crawlers. Off-page optimization consists of building links from other websites to your own, and technical SEO involves optimizing the underlying technology of your website to ensure it is properly indexed by search engines.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[27]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGLM-6B + LoRA "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGLM-6B 是一个开源的、支持中英双语问答的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。  \n",
    "结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。  \n",
    "ChatGLM-6B 使用了和 ChatGLM 相同的技术，针对中文问答和对话进行了优化。  \n",
    "经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823a00a06b6c45cc9db1b02bb7519d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True).half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7099b482f1474c44bf86edad5237bc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, Tuple, Union, Optional\n",
    "\n",
    "from torch.nn import Module\n",
    "\n",
    "def auto_configure_device_map(num_gpus: int) -> Dict[str, int]:\n",
    "    # transformer.word_embeddings 占用1层\n",
    "    # transformer.final_layernorm 和 lm_head 占用1层\n",
    "    # transformer.layers 占用 28 层\n",
    "    # 总共30层分配到num_gpus张卡上\n",
    "    num_trans_layers = 28\n",
    "    per_gpu_layers = 30 / num_gpus\n",
    "\n",
    "    # bugfix: 在linux中调用torch.embedding传入的weight,input不在同一device上,导致RuntimeError\n",
    "    # windows下 model.device 会被设置成 transformer.word_embeddings.device\n",
    "    # linux下 model.device 会被设置成 lm_head.device\n",
    "    # 在调用chat或者stream_chat时,input_ids会被放到model.device上\n",
    "    # 如果transformer.word_embeddings.device和model.device不同,则会导致RuntimeError\n",
    "    # 因此这里将transformer.word_embeddings,transformer.final_layernorm,lm_head都放到第一张卡上\n",
    "    device_map = {'transformer.word_embeddings': 0,\n",
    "                  'transformer.final_layernorm': 0, \n",
    "                  'lm_head': 0}\n",
    "\n",
    "    used = 2\n",
    "    gpu_target = 0\n",
    "    for i in range(num_trans_layers):\n",
    "        if used >= per_gpu_layers:\n",
    "            gpu_target += 1\n",
    "            used = 0\n",
    "        assert gpu_target < num_gpus\n",
    "        device_map[f'transformer.layers.{i}'] = gpu_target\n",
    "        used += 1\n",
    "\n",
    "    return device_map\n",
    "\n",
    "def load_model_on_gpus(checkpoint_path: Union[str, os.PathLike], num_gpus: int = 2,\n",
    "                       device_map: Optional[Dict[str, int]] = None, **kwargs) -> Module:\n",
    "    if num_gpus < 2 and device_map is None:\n",
    "        model = AutoModel.from_pretrained(checkpoint_path, trust_remote_code=True, **kwargs).half().cuda()\n",
    "    else:\n",
    "        from accelerate import dispatch_model\n",
    "\n",
    "        model = AutoModel.from_pretrained(checkpoint_path, trust_remote_code=True, **kwargs).half()\n",
    "\n",
    "        if device_map is None:\n",
    "            device_map = auto_configure_device_map(num_gpus)\n",
    "\n",
    "        model = dispatch_model(model, device_map=device_map)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model_on_gpus(\"THUDM/chatglm-6b\", num_gpus=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dtype of attention mask (torch.int64) is not bool\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"你好\", history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好👋！我是人工智能助手 ChatGLM-6B，很高兴见到你，欢迎问我任何问题。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"现在怎么入手nlp?\", history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP 是自然语言处理(Natural Language Processing)的缩写，是一种人工智能技术，旨在使计算机理解和解释人类语言。如果您想入手 NLP，以下是一些步骤：\\n\\n1. 学习自然语言处理的基础知识：了解自然语言处理的基本概念、技术和应用，例如文本预处理、文本分类、命名实体识别、情感分析、机器翻译等。\\n\\n2. 掌握编程技能：自然语言处理需要编程技能，因此您需要掌握至少一门编程语言，例如 Python、Java 等。\\n\\n3. 学习 NLP 框架：了解常用的自然语言处理框架，例如 NLTK、 spaCy、 Gensim 等。\\n\\n4. 实践项目：通过实践项目来巩固所学知识，例如通过构建一个简单的文本分类器、情感分析系统等。\\n\\n5. 参加在线课程或培训：参加在线课程或培训可以为您提供专业的指导和学习资源，例如Coursera、Udacity、edX等。\\n\\n6. 加入社区：加入自然语言处理相关的社区可以为您提供与其他学习者和专业人士交流的机会，例如 Stack Overflow、GitHub 等。\\n\\n希望这些步骤可以帮助您入门自然语言处理领域。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"我来自华北电力大学\", history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很高兴听到您来自华北电力大学！作为一个人工智能助手，我可以回答您的问题，提供帮助和信息。如果您有任何问题，请随时问我。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"按照我上面告诉你的信息，我来自哪儿\", history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据您提供的信息，您来自华北电力大学。作为一个人工智能助手，我无法验证您提供的信息的准确性，但我希望这些信息对您有所帮助。如果您有任何问题，请随时问我。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "电力系统是指将电能从发电站传输到用电设备的系统，是现代社会电力供应的基础。以下是电力系统的一些评价方面：\n",
       "\n",
       "1. 可靠性：电力系统的可靠性对于电力供应的稳定性至关重要。电力系统的设计和运行需要考虑到各种因素，如发电站和用电设备的故障率、电力传输的延迟和中断等，确保电力系统的可靠运行。\n",
       "\n",
       "2. 效率：电力系统的效率指的是其能量利用效率，即电力系统将能量从发电站传输到用电设备的效率。高效的电力系统可以减少能源浪费和损失，提高能源利用效率。\n",
       "\n",
       "3. 可持续性：电力系统的可持续性需要考虑其环境影响和资源利用。现代电力系统通常采用可再生能源发电，以减少对化石燃料的依赖和对环境的污染。同时，电力系统的可持续性还考虑其能源消耗和能源储存的可持续性。\n",
       "\n",
       "4. 安全性：电力系统的安全性包括各种安全措施，如电力保障、人员安全、设备保护等，以确保电力系统的正常运行和安全运行。\n",
       "\n",
       "5. 成本效益：电力系统的成本效益需要考虑其经济效益，即电力系统的能源成本、建设成本、运营成本等与能源价格的关系。高能源价格可能导致电力系统成本上升，但低能源价格则可能导致电力系统成本下降。\n",
       "\n",
       "电力系统是一个复杂的系统，需要考虑多个方面的评价，包括可靠性、效率、可持续性、安全性和成本效益等。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "prompt = \"从多方面评价电力系统\"\n",
    "for response, history in model.stream_chat(\n",
    "        tokenizer, prompt, history=[]):\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
